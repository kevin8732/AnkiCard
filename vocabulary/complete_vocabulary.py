import os
import re
from typing import List, Dict, Tuple
import time
import random

class VocabularyCompleter:
    """æ—¥è¯­è¯æ±‡ä¾‹å¥è‡ªåŠ¨è¡¥å…¨å·¥å…·"""
    
    def __init__(self):
        # é¢„è®¾çš„å¸¸ç”¨ä¾‹å¥æ¨¡æ¿å’Œè¯æ±‡å¯¹åº”çš„ä¾‹å¥
        self.example_templates = {
            # åŠ¨è¯ç±»ä¾‹å¥æ¨¡æ¿
            'verb_patterns': [
                "æ¯æ—¥{}ã¾ã™ã€‚",
                "ä»Šæ—¥ã¯{}ã¾ã—ãŸã€‚", 
                "æ˜æ—¥{}ã¤ã‚‚ã‚Šã§ã™ã€‚",
                "{}ã“ã¨ãŒã§ãã¾ã™ã€‚",
                "ã‚ˆã{}ã¾ã™ã€‚",
                "æ™‚ã€…{}ã¾ã™ã€‚",
                "ä¸€ç·’ã«{}ã¾ã—ã‚‡ã†ã€‚"
            ],
            
            # åè¯ç±»ä¾‹å¥æ¨¡æ¿
            'noun_patterns': [
                "ã“ã‚Œã¯{}ã§ã™ã€‚",
                "{}ãŒå¥½ãã§ã™ã€‚",
                "{}ã‚’è²·ã„ã¾ã—ãŸã€‚",
                "{}ã¯ã¨ã¦ã‚‚å¤§åˆ‡ã§ã™ã€‚",
                "{}ã«ã¤ã„ã¦è©±ã—ã¾ã™ã€‚",
                "æ–°ã—ã„{}ã§ã™ã€‚",
                "{}ã‚’æŒã£ã¦ã„ã¾ã™ã€‚"
            ],
            
            # å½¢å®¹è¯ç±»ä¾‹å¥æ¨¡æ¿
            'adjective_patterns': [
                "ã¨ã¦ã‚‚{}ã§ã™ã€‚",
                "{}å¤©æ°—ã§ã™ã­ã€‚",
                "{}äººã§ã™ã€‚",
                "{}ã¨ã“ã‚ã§ã™ã€‚",
                "{}æ°—æŒã¡ã§ã™ã€‚"
            ]
        }
        
        # å…·ä½“è¯æ±‡çš„ä¸“ç”¨ä¾‹å¥åº“
        self.specific_examples = {
            # å­¦ä¹ ç›¸å…³
            "å‹‰å¼·": ("æ¯æ—¥æ—¥æœ¬èªã‚’å‹‰å¼·ã—ã¾ã™", "æ¯å¤©å­¦ä¹ æ—¥è¯­"),
            "å­¦æ ¡": ("å­¦æ ¡ã«è¡Œãã¾ã™", "å»å­¦æ ¡"),
            "å…ˆç”Ÿ": ("å…ˆç”Ÿã«è³ªå•ã—ã¾ã™", "å‘è€å¸ˆæé—®"),
            "å­¦ç”Ÿ": ("ç§ã¯å¤§å­¦ç”Ÿã§ã™", "æˆ‘æ˜¯å¤§å­¦ç”Ÿ"),
            "æˆæ¥­": ("æˆæ¥­ãŒå§‹ã¾ã‚Šã¾ã™", "ä¸Šè¯¾å¼€å§‹äº†"),
            "å®¿é¡Œ": ("å®¿é¡Œã‚’å¿˜ã‚Œã¾ã—ãŸ", "å¿˜è®°å¸¦ä½œä¸šäº†"),
            "è©¦é¨“": ("æ¥é€±è©¦é¨“ãŒã‚ã‚Šã¾ã™", "ä¸‹å‘¨æœ‰è€ƒè¯•"),
            "æ•™ç§‘æ›¸": ("æ•™ç§‘æ›¸ã‚’é–‹ã„ã¦ãã ã•ã„", "è¯·æ‰“å¼€æ•™ç§‘ä¹¦"),
            
            # å·¥ä½œç›¸å…³
            "ä»•äº‹": ("ä»•äº‹ãŒå¿™ã—ã„ã§ã™", "å·¥ä½œå¾ˆå¿™"),
            "ä¼šç¤¾": ("ä¼šç¤¾å“¡ã¨ã—ã¦åƒã„ã¦ã„ã¾ã™", "ä½œä¸ºå…¬å¸å‘˜å·¥å·¥ä½œ"),
            "ä¼šè­°": ("åˆå¾Œä¼šè­°ãŒã‚ã‚Šã¾ã™", "ä¸‹åˆæœ‰ä¼šè®®"),
            "ç¤¾é•·": ("ç¤¾é•·ã¨è©±ã—ã¾ã—ãŸ", "å’Œç¤¾é•¿è°ˆè¯äº†"),
            "éƒ¨é•·": ("éƒ¨é•·ã¯å„ªã—ã„äººã§ã™", "éƒ¨é•¿æ˜¯ä¸ªæ¸©å’Œçš„äºº"),
            "åŒåƒš": ("åŒåƒšã¨æ˜¼é£Ÿã‚’é£Ÿã¹ã¾ã™", "å’ŒåŒäº‹åƒåˆé¥­"),
            "çµ¦æ–™": ("çµ¦æ–™ãŒä¸ŠãŒã‚Šã¾ã—ãŸ", "å·¥èµ„æ¶¨äº†"),
            "æ®‹æ¥­": ("ä»Šæ—¥ã¯æ®‹æ¥­ã—ã¾ã™", "ä»Šå¤©è¦åŠ ç­"),
            
            # å®¶æ—ç›¸å…³
            "å®¶æ—": ("å®¶æ—ã¨æ—…è¡Œã—ã¾ã™", "å’Œå®¶äººæ—…è¡Œ"),
            "ä¸¡è¦ª": ("ä¸¡è¦ªã«é›»è©±ã—ã¾ã™", "ç»™çˆ¶æ¯æ‰“ç”µè¯"),
            "çˆ¶": ("çˆ¶ã¯ä¼šç¤¾å“¡ã§ã™", "çˆ¶äº²æ˜¯å…¬å¸å‘˜å·¥"),
            "æ¯": ("æ¯ã¯æ–™ç†ãŒä¸Šæ‰‹ã§ã™", "æ¯äº²å¾ˆä¼šåšèœ"),
            "å…„": ("å…„ã¯åŒ»è€…ã§ã™", "å“¥å“¥æ˜¯åŒ»ç”Ÿ"),
            "å¼Ÿ": ("å¼Ÿã¨æ˜ ç”»ã‚’è¦‹ã¾ã™", "å’Œå¼Ÿå¼Ÿçœ‹ç”µå½±"),
            "å§‰": ("å§‰ã¯çµå©šã—ã¾ã—ãŸ", "å§å§ç»“å©šäº†"),
            "å¦¹": ("å¦¹ã¯é«˜æ ¡ç”Ÿã§ã™", "å¦¹å¦¹æ˜¯é«˜ä¸­ç”Ÿ"),
            "å­ã©ã‚‚": ("å­ã©ã‚‚ãŒä¸‰äººã„ã¾ã™", "æœ‰ä¸‰ä¸ªå­©å­"),
            "å¤«": ("å¤«ã¨è²·ã„ç‰©ã«è¡Œãã¾ã™", "å’Œä¸ˆå¤«å»è´­ç‰©"),
            "å¦»": ("å¦»ã¯çœ‹è­·å¸«ã§ã™", "å¦»å­æ˜¯æŠ¤å£«"),
            
            # é£Ÿç‰©ç›¸å…³
            "é£Ÿã¹ç‰©": ("ç¾å‘³ã—ã„é£Ÿã¹ç‰©ã‚’ä½œã‚Šã¾ã™", "åšç¾å‘³çš„é£Ÿç‰©"),
            "æ–™ç†": ("æ—¥æœ¬æ–™ç†ãŒå¥½ãã§ã™", "å–œæ¬¢æ—¥æœ¬æ–™ç†"),
            "æœã”é£¯": ("æœã”é£¯ã‚’é£Ÿã¹ã¾ã—ã‚‡ã†", "åƒæ—©é¥­å§"),
            "æ˜¼ã”é£¯": ("æ˜¼ã”é£¯ã®æ™‚é–“ã§ã™", "åˆ°äº†åƒåˆé¥­çš„æ—¶é—´"),
            "æ™©ã”é£¯": ("æ™©ã”é£¯ã‚’ä½œã‚Šã¾ã™", "åšæ™šé¥­"),
            "ãƒ‘ãƒ³": ("æœã¯ãƒ‘ãƒ³ã‚’é£Ÿã¹ã¾ã™", "æ—©ä¸Šåƒé¢åŒ…"),
            "ã”é£¯": ("ã”é£¯ã‚’ç‚Šãã¾ã™", "ç…®ç±³é¥­"),
            "è‚‰": ("è‚‰ã‚’ãŸãã•ã‚“é£Ÿã¹ã¾ã™", "åƒå¾ˆå¤šè‚‰"),
            "é­š": ("é­šãŒæ–°é®®ã§ã™", "é±¼å¾ˆæ–°é²œ"),
            "é‡èœ": ("é‡èœã¯å¥åº·ã«ã„ã„ã§ã™", "è”¬èœå¯¹å¥åº·æœ‰å¥½å¤„"),
            
            # é¥®å“ç›¸å…³
            "æ°´": ("å†·ãŸã„æ°´ã‚’é£²ã¿ã¾ã™", "å–å†·æ°´"),
            "ãŠèŒ¶": ("ãŠèŒ¶ã‚’ã„ã‚Œã¾ã™", "æ³¡èŒ¶"),
            "ã‚³ãƒ¼ãƒ’ãƒ¼": ("æœã¯ã‚³ãƒ¼ãƒ’ãƒ¼ã‚’é£²ã¿ã¾ã™", "æ—©ä¸Šå–å’–å•¡"),
            "ãƒ“ãƒ¼ãƒ«": ("ãƒ“ãƒ¼ãƒ«ã§ä¹¾æ¯ã—ã¾ã™", "ç”¨å•¤é…’å¹²æ¯"),
            "ã‚¸ãƒ¥ãƒ¼ã‚¹": ("ã‚ªãƒ¬ãƒ³ã‚¸ã‚¸ãƒ¥ãƒ¼ã‚¹ãŒå¥½ãã§ã™", "å–œæ¬¢æ©™æ±"),
            "ç‰›ä¹³": ("æ¯æ—¥ç‰›ä¹³ã‚’é£²ã¿ã¾ã™", "æ¯å¤©å–ç‰›å¥¶"),
            
            # äº¤é€šç›¸å…³
            "é›»è»Š": ("é›»è»Šã§é€šå‹¤ã—ã¾ã™", "åç”µè½¦é€šå‹¤"),
            "ãƒã‚¹": ("ãƒã‚¹ãŒé…ã‚Œã¦ã„ã¾ã™", "å…¬äº¤è½¦æ™šç‚¹äº†"),
            "ã‚¿ã‚¯ã‚·ãƒ¼": ("ã‚¿ã‚¯ã‚·ãƒ¼ã‚’å‘¼ã³ã¾ã™", "å«å‡ºç§Ÿè½¦"),
            "é£›è¡Œæ©Ÿ": ("é£›è¡Œæ©Ÿã§æ—…è¡Œã—ã¾ã™", "åé£æœºæ—…è¡Œ"),
            "è‡ªå‹•è»Š": ("æ–°ã—ã„è‡ªå‹•è»Šã‚’è²·ã„ã¾ã—ãŸ", "ä¹°äº†æ–°è½¦"),
            "è‡ªè»¢è»Š": ("è‡ªè»¢è»Šã§å­¦æ ¡ã«è¡Œãã¾ã™", "éª‘è‡ªè¡Œè½¦å»å­¦æ ¡"),
            "é§…": ("é§…ã§å¾…ã¡åˆã‚ã›ã¾ã™", "åœ¨è½¦ç«™ç¢°é¢"),
            "ç©ºæ¸¯": ("ç©ºæ¸¯ã«ç€ãã¾ã—ãŸ", "åˆ°è¾¾æœºåœºäº†"),
            
            # å¤©æ°”ç›¸å…³
            "å¤©æ°—": ("ä»Šæ—¥ã¯ã„ã„å¤©æ°—ã§ã™ã­", "ä»Šå¤©å¤©æ°”çœŸå¥½å•Š"),
            "é›¨": ("é›¨ãŒé™ã£ã¦ã„ã¾ã™", "æ­£åœ¨ä¸‹é›¨"),
            "é›ª": ("é›ªãŒãŸãã•ã‚“ç©ã‚‚ã‚Šã¾ã—ãŸ", "é›ªç§¯äº†å¾ˆå¤š"),
            "é¢¨": ("é¢¨ãŒå¼·ã„ã§ã™", "é£å¾ˆå¤§"),
            "æš‘ã„": ("ä»Šæ—¥ã¯ã¨ã¦ã‚‚æš‘ã„ã§ã™", "ä»Šå¤©å¾ˆçƒ­"),
            "å¯’ã„": ("å†¬ã¯å¯’ã„ã§ã™", "å†¬å¤©å¾ˆå†·"),
            "æ¶¼ã—ã„": ("ç§‹ã¯æ¶¼ã—ã„ã§ã™", "ç§‹å¤©å¾ˆå‡‰çˆ½"),
            "æš–ã‹ã„": ("æ˜¥ã¯æš–ã‹ã„ã§ã™", "æ˜¥å¤©å¾ˆæ¸©æš–"),
            
            # æ—¶é—´ç›¸å…³
            "æ™‚é–“": ("æ™‚é–“ãŒã‚ã‚Šã¾ã›ã‚“", "æ²¡æœ‰æ—¶é—´"),
            "ä»Šæ—¥": ("ä»Šæ—¥ã¯å¿™ã—ã„æ—¥ã§ã™", "ä»Šå¤©æ˜¯å¿™ç¢Œçš„ä¸€å¤©"),
            "æ˜¨æ—¥": ("æ˜¨æ—¥æ˜ ç”»ã‚’è¦‹ã¾ã—ãŸ", "æ˜¨å¤©çœ‹äº†ç”µå½±"),
            "æ˜æ—¥": ("æ˜æ—¥æ—©ãèµ·ãã¾ã™", "æ˜å¤©æ—©èµ·"),
            "æœ": ("æœæ—©ãèµ·ãã¾ã™", "æ—©ä¸Šæ—©èµ·"),
            "æ˜¼": ("æ˜¼ä¼‘ã¿ã«æ•£æ­©ã—ã¾ã™", "åˆä¼‘æ—¶æ•£æ­¥"),
            "å¤œ": ("å¤œé…ãã¾ã§å‹‰å¼·ã—ã¾ã™", "å­¦ä¹ åˆ°æ·±å¤œ"),
            "é€±æœ«": ("é€±æœ«ã«å‹é”ã¨ä¼šã„ã¾ã™", "å‘¨æœ«å’Œæœ‹å‹è§é¢"),
            
            # æ„Ÿæƒ…ç›¸å…³
            "å¬‰ã—ã„": ("ã¨ã¦ã‚‚å¬‰ã—ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹ã§ã™", "æ˜¯éå¸¸é«˜å…´çš„æ¶ˆæ¯"),
            "æ‚²ã—ã„": ("æ‚²ã—ã„æ˜ ç”»ã§ã—ãŸ", "æ˜¯æ‚²ä¼¤çš„ç”µå½±"),
            "æ¥½ã—ã„": ("ãƒ‘ãƒ¼ãƒ†ã‚£ãƒ¼ã¯ã¨ã¦ã‚‚æ¥½ã—ã‹ã£ãŸã§ã™", "èšä¼šéå¸¸æ„‰å¿«"),
            "å¿ƒé…": ("æ¯ã®ã“ã¨ãŒå¿ƒé…ã§ã™", "æ‹…å¿ƒæ¯äº²"),
            "å®‰å¿ƒ": ("ã‚„ã£ã¨å®‰å¿ƒã—ã¾ã—ãŸ", "ç»ˆäºå®‰å¿ƒäº†"),
            "é©šã": ("ãã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã«é©šãã¾ã—ãŸ", "å¯¹é‚£ä¸ªæ¶ˆæ¯æ„Ÿåˆ°æƒŠè®¶"),
            
            # é¢œè‰²ç›¸å…³
            "èµ¤": ("èµ¤ã„ãƒãƒ©ãŒç¾ã—ã„ã§ã™", "çº¢ç«ç‘°å¾ˆç¾ä¸½"),
            "é’": ("é’ã„ç©ºãŒåºƒãŒã£ã¦ã„ã¾ã™", "è“å¤©å¹¿é˜”"),
            "ç™½": ("ç™½ã„ã‚·ãƒ£ãƒ„ã‚’ç€ã¦ã„ã¾ã™", "ç©¿ç€ç™½è¡¬è¡«"),
            "é»’": ("é»’ã„çŒ«ãŒã„ã¾ã™", "æœ‰ä¸€åªé»‘çŒ«"),
            "ç·‘": ("ç·‘ã®æœ¨ãŒãŸãã•ã‚“ã‚ã‚Šã¾ã™", "æœ‰å¾ˆå¤šç»¿æ ‘"),
            "é»„è‰²": ("é»„è‰²ã„èŠ±ãŒå’²ã„ã¦ã„ã¾ã™", "é»„èŠ±ç››å¼€"),
            
            # è´­ç‰©ç›¸å…³
            "è²·ã„ç‰©": ("ã‚¹ãƒ¼ãƒ‘ãƒ¼ã§è²·ã„ç‰©ã—ã¾ã™", "åœ¨è¶…å¸‚è´­ç‰©"),
            "åº—": ("æ–°ã—ã„åº—ãŒã‚ªãƒ¼ãƒ—ãƒ³ã—ã¾ã—ãŸ", "æ–°åº—å¼€ä¸šäº†"),
            "ãŠé‡‘": ("ãŠé‡‘ã‚’è²¯ã‚ã¦ã„ã¾ã™", "åœ¨å­˜é’±"),
            "å€¤æ®µ": ("å€¤æ®µãŒé«˜ã™ãã¾ã™", "ä»·æ ¼å¤ªé«˜äº†"),
            "å®‰ã„": ("ã“ã®æœã¯å®‰ã„ã§ã™", "è¿™ä»¶è¡£æœä¾¿å®œ"),
            "é«˜ã„": ("ãã®ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³ã¯é«˜ã„ã§ã™", "é‚£å®¶é¤å…å¾ˆè´µ"),
            
            # èº«ä½“ç›¸å…³
            "ä½“": ("æ¯æ—¥ä½“ã‚’é›ãˆã¾ã™", "æ¯å¤©é”»ç‚¼èº«ä½“"),
            "é ­": ("é ­ãŒç—›ã„ã§ã™", "å¤´ç–¼"),
            "ç›®": ("ç›®ãŒç–²ã‚Œã¾ã—ãŸ", "çœ¼ç›ç´¯äº†"),
            "è€³": ("éŸ³æ¥½ã‚’è€³ã§èãã¾ã™", "ç”¨è€³æœµå¬éŸ³ä¹"),
            "å£": ("å£ã‚’é–‹ã‘ã¦ãã ã•ã„", "è¯·å¼ å¼€å˜´"),
            "æ‰‹": ("æ‰‹ã‚’æ´—ã„ã¾ã™", "æ´—æ‰‹"),
            "è¶³": ("è¶³ãŒç—›ã„ã§ã™", "è„šç–¼"),
            
            # æˆ¿å±‹ç›¸å…³
            "å®¶": ("å®¶ã«å¸°ã‚Šã¾ã™", "å›å®¶"),
            "éƒ¨å±‹": ("éƒ¨å±‹ã‚’æƒé™¤ã—ã¾ã™", "æ‰“æ‰«æˆ¿é—´"),
            "ã‚­ãƒƒãƒãƒ³": ("ã‚­ãƒƒãƒãƒ³ã§æ–™ç†ã—ã¾ã™", "åœ¨å¨æˆ¿åšèœ"),
            "ãƒˆã‚¤ãƒ¬": ("ãƒˆã‚¤ãƒ¬ã¯ã©ã“ã§ã™ã‹", "å•æ‰€åœ¨å“ªé‡Œ"),
            "ãƒ™ãƒƒãƒ‰": ("ãƒ™ãƒƒãƒ‰ã§ä¼‘ã¿ã¾ã™", "åœ¨åºŠä¸Šä¼‘æ¯"),
            "çª“": ("çª“ã‚’é–‹ã‘ã¾ã™", "æ‰“å¼€çª—æˆ·"),
            "ãƒ‰ã‚¢": ("ãƒ‰ã‚¢ã‚’ãƒãƒƒã‚¯ã—ã¾ã™", "æ•²é—¨"),
            
            # æ•°å­—ç›¸å…³
            "ä¸€": ("ä¸€ã¤ãã ã•ã„", "è¯·ç»™æˆ‘ä¸€ä¸ª"),
            "äºŒ": ("äºŒäººã§é£Ÿäº‹ã—ã¾ã™", "ä¸¤äººåƒé¥­"),
            "ä¸‰": ("ä¸‰æ™‚ã«ä¼šã„ã¾ã—ã‚‡ã†", "ä¸‰ç‚¹è§é¢å§"),
            "å": ("ååˆ†å¾…ã£ã¦ãã ã•ã„", "è¯·ç­‰ååˆ†é’Ÿ"),
            "ç™¾": ("ç™¾å††ã‚·ãƒ§ãƒƒãƒ—ã§è²·ã„ã¾ã™", "åœ¨ç™¾å…ƒåº—ä¹°"),
            "åƒ": ("åƒå††æœ­ã‚’ä¸¡æ›¿ã—ã¾ã™", "å…‘æ¢åƒå…ƒçº¸å¸"),
            "ä¸‡": ("ä¸€ä¸‡å††ã‹ã‹ã‚Šã¾ã™", "éœ€è¦ä¸€ä¸‡æ—¥å…ƒ")
        }

    def read_vocabulary_file(self, file_path: str) -> List[Dict]:
        """è¯»å–è¯æ±‡æ–‡ä»¶"""
        vocabulary_list = []
        current_section = ""
        
        if not os.path.exists(file_path):
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return vocabulary_list
            
        with open(file_path, 'r', encoding='utf-8') as file:
            for line_num, line in enumerate(file, 1):
                line = line.strip()
                
                if not line:
                    continue
                    
                # æ£€æµ‹ç« èŠ‚æ ‡é¢˜
                if line.startswith('ã€') and line.endswith('ã€‘'):
                    current_section = line[1:-1]
                    continue
                
                # è§£æè¯æ±‡è¡Œ
                if '|' in line:
                    parts = line.split('|')
                    if len(parts) >= 3:
                        word = parts[0].strip()
                        pronunciation = parts[1].strip()
                        meaning = parts[2].strip()
                        
                        # å¤„ç†ä¾‹å¥
                        example = parts[3].strip() if len(parts) > 3 else ""
                        example_trans = parts[4].strip() if len(parts) > 4 else ""
                        
                        vocabulary_list.append({
                            'word': word,
                            'pronunciation': pronunciation,
                            'meaning': meaning,
                            'example': example,
                            'example_trans': example_trans,
                            'section': current_section,
                            'line_num': line_num,
                            'needs_completion': not (example and example_trans)
                        })
                    else:
                        print(f"âš ï¸ ç¬¬{line_num}è¡Œæ ¼å¼ä¸æ­£ç¡®: {line}")
        
        return vocabulary_list

    def generate_example_for_word(self, word: str, pronunciation: str, meaning: str) -> Tuple[str, str]:
        """ä¸ºå•è¯ç”Ÿæˆä¾‹å¥å’Œç¿»è¯‘"""
        
        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æœ‰é¢„è®¾çš„ä¾‹å¥
        if word in self.specific_examples:
            return self.specific_examples[word]
        
        # æ ¹æ®è¯æ€§å’Œå«ä¹‰ç”Ÿæˆä¾‹å¥
        example_jp, example_cn = self._create_contextual_example(word, pronunciation, meaning)
        
        return example_jp, example_cn

    def _create_contextual_example(self, word: str, pronunciation: str, meaning: str) -> Tuple[str, str]:
        """æ ¹æ®ä¸Šä¸‹æ–‡åˆ›å»ºä¾‹å¥"""
        
        # åˆ¤æ–­è¯æ€§å¹¶é€‰æ‹©åˆé€‚çš„ä¾‹å¥æ¨¡æ¿
        if self._is_verb(word, meaning):
            pattern = random.choice(self.example_templates['verb_patterns'])
            example_jp = pattern.format(word)
            example_cn = f"ä½¿ç”¨ã€Œ{word}ã€çš„ä¾‹å¥ï¼š{self._translate_pattern(pattern, word, meaning)}"
        
        elif self._is_adjective(word, meaning):
            pattern = random.choice(self.example_templates['adjective_patterns'])
            example_jp = pattern.format(word)
            example_cn = f"ä½¿ç”¨ã€Œ{word}ã€çš„ä¾‹å¥ï¼š{self._translate_pattern(pattern, word, meaning)}"
        
        else:  # é»˜è®¤å½“ä½œåè¯å¤„ç†
            pattern = random.choice(self.example_templates['noun_patterns'])
            example_jp = pattern.format(word)
            example_cn = f"ä½¿ç”¨ã€Œ{word}ã€çš„ä¾‹å¥ï¼š{self._translate_pattern(pattern, word, meaning)}"
        
        return example_jp, example_cn

    def _is_verb(self, word: str, meaning: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºåŠ¨è¯"""
        verb_indicators = ['ã™ã‚‹', 'ã„ã¾ã™', 'ã¾ã™', 'åŠ¨', 'åš', 'å»', 'æ¥', 'çœ‹', 'å¬', 'è¯´', 'è¯»', 'å†™', 'åƒ', 'å–', 'ä¹°', 'å–', 'å·¥ä½œ', 'å­¦ä¹ ', 'ç¡è§‰', 'èµ·åºŠ']
        return any(indicator in word or indicator in meaning for indicator in verb_indicators)

    def _is_adjective(self, word: str, meaning: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºå½¢å®¹è¯"""
        adj_indicators = ['ã„', 'çš„', 'å¥½', 'å', 'å¤§', 'å°', 'æ–°', 'æ—§', 'é«˜', 'ä½', 'é•¿', 'çŸ­', 'å¿«', 'æ…¢', 'çƒ­', 'å†·', 'æš–', 'å‡‰']
        return any(indicator in word[-1:] or indicator in meaning for indicator in adj_indicators)

    def _translate_pattern(self, pattern: str, word: str, meaning: str) -> str:
        """ç®€å•çš„æ¨¡æ¿ç¿»è¯‘"""
        translations = {
            "æ¯æ—¥{}ã¾ã™ã€‚": f"æ¯å¤©{meaning}",
            "ä»Šæ—¥ã¯{}ã¾ã—ãŸã€‚": f"ä»Šå¤©{meaning}äº†", 
            "æ˜æ—¥{}ã¤ã‚‚ã‚Šã§ã™ã€‚": f"æ˜å¤©æ‰“ç®—{meaning}",
            "{}ã“ã¨ãŒã§ãã¾ã™ã€‚": f"èƒ½å¤Ÿ{meaning}",
            "ã‚ˆã{}ã¾ã™ã€‚": f"ç»å¸¸{meaning}",
            "æ™‚ã€…{}ã¾ã™ã€‚": f"æœ‰æ—¶{meaning}",
            "ä¸€ç·’ã«{}ã¾ã—ã‚‡ã†ã€‚": f"ä¸€èµ·{meaning}å§",
            
            "ã“ã‚Œã¯{}ã§ã™ã€‚": f"è¿™æ˜¯{meaning}",
            "{}ãŒå¥½ãã§ã™ã€‚": f"å–œæ¬¢{meaning}",
            "{}ã‚’è²·ã„ã¾ã—ãŸã€‚": f"ä¹°äº†{meaning}",
            "{}ã¯ã¨ã¦ã‚‚å¤§åˆ‡ã§ã™ã€‚": f"{meaning}å¾ˆé‡è¦",
            "{}ã«ã¤ã„ã¦è©±ã—ã¾ã™ã€‚": f"è°ˆè®º{meaning}",
            "æ–°ã—ã„{}ã§ã™ã€‚": f"æ–°çš„{meaning}",
            "{}ã‚’æŒã£ã¦ã„ã¾ã™ã€‚": f"æœ‰{meaning}",
            
            "ã¨ã¦ã‚‚{}ã§ã™ã€‚": f"éå¸¸{meaning}",
            "{}å¤©æ°—ã§ã™ã­ã€‚": f"{meaning}çš„å¤©æ°”å‘¢",
            "{}äººã§ã™ã€‚": f"{meaning}çš„äºº",
            "{}ã¨ã“ã‚ã§ã™ã€‚": f"{meaning}çš„åœ°æ–¹",
            "{}æ°—æŒã¡ã§ã™ã€‚": f"{meaning}çš„å¿ƒæƒ…"
        }
        
        return translations.get(pattern, f"å…³äº{meaning}çš„å¥å­")

    def complete_vocabulary(self, vocabulary_list: List[Dict]) -> List[Dict]:
        """è¡¥å…¨ç¼ºå°‘ä¾‹å¥çš„è¯æ±‡"""
        print("ğŸ” å¼€å§‹åˆ†æè¯æ±‡æ–‡ä»¶...")
        
        incomplete_count = 0
        completed_count = 0
        
        for vocab in vocabulary_list:
            if vocab['needs_completion']:
                incomplete_count += 1
                print(f"ğŸ“ è¡¥å…¨ä¾‹å¥: {vocab['word']} ({vocab['meaning']})")
                
                # ç”Ÿæˆä¾‹å¥
                example_jp, example_cn = self.generate_example_for_word(
                    vocab['word'], 
                    vocab['pronunciation'], 
                    vocab['meaning']
                )
                
                # æ›´æ–°è¯æ±‡ä¿¡æ¯
                vocab['example'] = example_jp
                vocab['example_trans'] = example_cn
                vocab['needs_completion'] = False
                completed_count += 1
                
                # æ·»åŠ å°å»¶è¿Ÿï¼Œé¿å…å¤„ç†è¿‡å¿«
                time.sleep(0.1)
        
        print(f"âœ… è¡¥å…¨å®Œæˆ: {completed_count}/{incomplete_count}")
        return vocabulary_list

    def write_vocabulary_file(self, vocabulary_list: List[Dict], output_path: str):
        """å†™å…¥è¡¥å…¨åçš„è¯æ±‡æ–‡ä»¶"""
        print(f"ğŸ’¾ ä¿å­˜è¡¥å…¨åçš„æ–‡ä»¶: {output_path}")
        
        # æŒ‰ç« èŠ‚åˆ†ç»„
        sections = {}
        for vocab in vocabulary_list:
            section = vocab['section']
            if section not in sections:
                sections[section] = []
            sections[section].append(vocab)
        
        with open(output_path, 'w', encoding='utf-8') as file:
            for section_name, words in sections.items():
                if section_name:
                    file.write(f"ã€{section_name}ã€‘\n")
                
                for word_data in words:
                    line = f"{word_data['word']}|{word_data['pronunciation']}|{word_data['meaning']}|{word_data['example']}|{word_data['example_trans']}\n"
                    file.write(line)
                
                file.write("\n")  # ç« èŠ‚é—´ç©ºè¡Œ

    def create_backup(self, original_file: str) -> str:
        """åˆ›å»ºåŸæ–‡ä»¶å¤‡ä»½"""
        backup_file = f"{original_file}.backup_{int(time.time())}"
        if os.path.exists(original_file):
            with open(original_file, 'r', encoding='utf-8') as src:
                with open(backup_file, 'w', encoding='utf-8') as dst:
                    dst.write(src.read())
            print(f"ğŸ“‹ å·²åˆ›å»ºå¤‡ä»½æ–‡ä»¶: {backup_file}")
        return backup_file

    def show_statistics(self, vocabulary_list: List[Dict]):
        """æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯"""
        total = len(vocabulary_list)
        incomplete = sum(1 for vocab in vocabulary_list if vocab['needs_completion'])
        complete = total - incomplete
        
        print(f"\nğŸ“Š è¯æ±‡æ–‡ä»¶ç»Ÿè®¡:")
        print(f"  æ€»è¯æ±‡æ•°: {total}")
        print(f"  å·²æœ‰ä¾‹å¥: {complete}")
        print(f"  éœ€è¦è¡¥å…¨: {incomplete}")
        print(f"  å®Œæ•´ç‡: {(complete/total*100):.1f}%")
        
        # æŒ‰ç« èŠ‚ç»Ÿè®¡
        sections = {}
        for vocab in vocabulary_list:
            section = vocab['section']
            if section not in sections:
                sections[section] = {'total': 0, 'incomplete': 0}
            sections[section]['total'] += 1
            if vocab['needs_completion']:
                sections[section]['incomplete'] += 1
        
        print(f"\nğŸ“š å„ç« èŠ‚ç»Ÿè®¡:")
        for section, stats in sections.items():
            complete_rate = ((stats['total'] - stats['incomplete']) / stats['total'] * 100) if stats['total'] > 0 else 0
            print(f"  {section}: {stats['total']}è¯æ±‡, {stats['incomplete']}å¾…è¡¥å…¨ ({complete_rate:.1f}%å®Œæ•´)")

def main():
    print("ğŸŒ æ—¥è¯­è¯æ±‡ä¾‹å¥è‡ªåŠ¨è¡¥å…¨å·¥å…·")
    print("=" * 50)
    
    completer = VocabularyCompleter()
    
    # æ–‡ä»¶è·¯å¾„
    script_dir = os.path.dirname(os.path.abspath(__file__))
    input_file = os.path.join(script_dir, 'n2_vocabulary.txt')
    output_file = os.path.join(script_dir, 'n2_vocabulary_completed.txt')
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(input_file):
        print(f"âŒ æ‰¾ä¸åˆ°è¯æ±‡æ–‡ä»¶: {input_file}")
        print("è¯·ç¡®ä¿ 'n2_vocabulary.txt' æ–‡ä»¶åœ¨è„šæœ¬åŒç›®å½•ä¸‹")
        return
    
    # è¯»å–è¯æ±‡æ–‡ä»¶
    vocabulary_list = completer.read_vocabulary_file(input_file)
    if not vocabulary_list:
        print("âŒ è¯æ±‡æ–‡ä»¶ä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯")
        return
    
    # æ˜¾ç¤ºåˆå§‹ç»Ÿè®¡
    completer.show_statistics(vocabulary_list)
    
    # ç¡®è®¤æ˜¯å¦ç»§ç»­
    incomplete_count = sum(1 for vocab in vocabulary_list if vocab['needs_completion'])
    if incomplete_count == 0:
        print("âœ… æ‰€æœ‰è¯æ±‡éƒ½å·²æœ‰ä¾‹å¥ï¼Œæ— éœ€è¡¥å…¨!")
        return
    
    print(f"\nğŸ’¡ å°†ä¸º {incomplete_count} ä¸ªè¯æ±‡è¡¥å…¨ä¾‹å¥")
    confirm = input("æ˜¯å¦ç»§ç»­? (y/N): ").lower().strip()
    
    if confirm not in ['y', 'yes', 'æ˜¯']:
        print("âŒ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
        return
    
    # åˆ›å»ºå¤‡ä»½
    completer.create_backup(input_file)
    
    # è¡¥å…¨è¯æ±‡
    completed_vocabulary = completer.complete_vocabulary(vocabulary_list)
    
    # ä¿å­˜ç»“æœ
    completer.write_vocabulary_file(completed_vocabulary, output_file)
    
    # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
    print(f"\nğŸ‰ è¡¥å…¨å®Œæˆ!")
    print(f"ğŸ“„ åŸæ–‡ä»¶: {input_file}")
    print(f"ğŸ“„ æ–°æ–‡ä»¶: {output_file}")
    print(f"ğŸ“‹ å¤‡ä»½æ–‡ä»¶å·²åˆ›å»º")
    
    # è¯¢é—®æ˜¯å¦æ›¿æ¢åŸæ–‡ä»¶
    replace = input(f"\næ˜¯å¦ç”¨è¡¥å…¨åçš„æ–‡ä»¶æ›¿æ¢åŸæ–‡ä»¶? (y/N): ").lower().strip()
    if replace in ['y', 'yes', 'æ˜¯']:
        os.replace(output_file, input_file)
        print(f"âœ… å·²æ›´æ–°åŸæ–‡ä»¶: {input_file}")
    else:
        print(f"ğŸ“ è¡¥å…¨åçš„æ–‡ä»¶ä¿å­˜ä¸º: {output_file}")
    
    print("\nâœ¨ æç¤º: å¯ä»¥æ‰‹åŠ¨æ£€æŸ¥å’Œä¿®æ”¹ç”Ÿæˆçš„ä¾‹å¥ä»¥ç¡®ä¿å‡†ç¡®æ€§")

if __name__ == "__main__":
    main()